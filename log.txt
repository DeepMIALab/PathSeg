Data Distribution For Training Phase
Images 812
Masks 812
Data Distribution For Validation Phase
Images 91
Masks 91
Feature info [{'num_chs': 64, 'reduction': 2, 'module': 'stem'}, {'num_chs': 128, 'reduction': 4, 'module': 'stage1'}, {'num_chs': 256, 'reduction': 8, 'module': 'stage2'}, {'num_chs': 512, 'reduction': 16, 'module': 'stage3'}, {'num_chs': 1024, 'reduction': 32, 'module': 'stage4'}]
Feature info [{'num_chs': 64, 'reduction': 2, 'module': 'stem'}, {'num_chs': 128, 'reduction': 4, 'module': 'stage1'}, {'num_chs': 256, 'reduction': 8, 'module': 'stage2'}, {'num_chs': 512, 'reduction': 16, 'module': 'stage3'}, {'num_chs': 1024, 'reduction': 32, 'module': 'stage4'}]
Model UnetPlusPlus(
  (encoder): HighResolutionNetFeatures(
    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU(inplace=True)
    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU(inplace=True)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (drop_block): Identity()
        (act2): ReLU(inplace=True)
        (aa): Identity()
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act3): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (cbam): CBAM(
          (channel_attention): Channel_Attention(
            (shared_mlp): Sequential(
              (0): Flatten(start_dim=1, end_dim=-1)
              (1): Linear(in_features=256, out_features=16, bias=True)
              (2): ReLU(inplace=True)
              (3): Linear(in_features=16, out_features=256, bias=True)
            )
          )
          (spatial_attention): Spatial_Attention(
            (compress): ChannelPool()
            (spatial_attention): Sequential(
              (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
              (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
            )
          )
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (drop_block): Identity()
        (act2): ReLU(inplace=True)
        (aa): Identity()
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act3): ReLU(inplace=True)
        (cbam): CBAM(
          (channel_attention): Channel_Attention(
            (shared_mlp): Sequential(
              (0): Flatten(start_dim=1, end_dim=-1)
              (1): Linear(in_features=256, out_features=16, bias=True)
              (2): ReLU(inplace=True)
              (3): Linear(in_features=16, out_features=256, bias=True)
            )
          )
          (spatial_attention): Spatial_Attention(
            (compress): ChannelPool()
            (spatial_attention): Sequential(
              (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
              (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
            )
          )
        )
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (drop_block): Identity()
        (act2): ReLU(inplace=True)
        (aa): Identity()
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act3): ReLU(inplace=True)
        (cbam): CBAM(
          (channel_attention): Channel_Attention(
            (shared_mlp): Sequential(
              (0): Flatten(start_dim=1, end_dim=-1)
              (1): Linear(in_features=256, out_features=16, bias=True)
              (2): ReLU(inplace=True)
              (3): Linear(in_features=16, out_features=256, bias=True)
            )
          )
          (spatial_attention): Spatial_Attention(
            (compress): ChannelPool()
            (spatial_attention): Sequential(
              (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
              (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
            )
          )
        )
      )
      (3): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act1): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (drop_block): Identity()
        (act2): ReLU(inplace=True)
        (aa): Identity()
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act3): ReLU(inplace=True)
        (cbam): CBAM(
          (channel_attention): Channel_Attention(
            (shared_mlp): Sequential(
              (0): Flatten(start_dim=1, end_dim=-1)
              (1): Linear(in_features=256, out_features=16, bias=True)
              (2): ReLU(inplace=True)
              (3): Linear(in_features=16, out_features=256, bias=True)
            )
          )
          (spatial_attention): Spatial_Attention(
            (compress): ChannelPool()
            (spatial_attention): Sequential(
              (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
              (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
            )
          )
        )
      )
    )
    (transition1): ModuleList(
      (0): Sequential(
        (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): Sequential(
        (0): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
    )
    (stage2): Sequential(
      (0): HighResolutionModule(
        (branches): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): Identity()
            (1): Sequential(
              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Identity()
          )
        )
        (fuse_act): ReLU()
      )
    )
    (transition2): ModuleList(
      (0): Identity()
      (1): Identity()
      (2): Sequential(
        (0): Sequential(
          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
    )
    (stage3): Sequential(
      (0): HighResolutionModule(
        (branches): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): Identity()
            (1): Sequential(
              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Identity()
            (2): Sequential(
              (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Identity()
          )
        )
        (fuse_act): ReLU()
      )
      (1): HighResolutionModule(
        (branches): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): Identity()
            (1): Sequential(
              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Identity()
            (2): Sequential(
              (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Identity()
          )
        )
        (fuse_act): ReLU()
      )
      (2): HighResolutionModule(
        (branches): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): Identity()
            (1): Sequential(
              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Identity()
            (2): Sequential(
              (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Identity()
          )
        )
        (fuse_act): ReLU()
      )
      (3): HighResolutionModule(
        (branches): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): Identity()
            (1): Sequential(
              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Identity()
            (2): Sequential(
              (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Identity()
          )
        )
        (fuse_act): ReLU()
      )
    )
    (transition3): ModuleList(
      (0): Identity()
      (1): Identity()
      (2): Identity()
      (3): Sequential(
        (0): Sequential(
          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
    )
    (stage4): Sequential(
      (0): HighResolutionModule(
        (branches): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (3): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=512, out_features=32, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=32, out_features=512, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=512, out_features=32, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=32, out_features=512, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=512, out_features=32, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=32, out_features=512, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=512, out_features=32, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=32, out_features=512, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): Identity()
            (1): Sequential(
              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=8.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Identity()
            (2): Sequential(
              (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Identity()
            (3): Sequential(
              (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (3): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (2): Sequential(
                (0): Conv2d(64, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(128, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Sequential(
              (0): Sequential(
                (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): Identity()
          )
        )
        (fuse_act): ReLU()
      )
      (1): HighResolutionModule(
        (branches): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (3): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=512, out_features=32, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=32, out_features=512, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=512, out_features=32, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=32, out_features=512, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=512, out_features=32, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=32, out_features=512, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=512, out_features=32, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=32, out_features=512, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): Identity()
            (1): Sequential(
              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=8.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Identity()
            (2): Sequential(
              (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Identity()
            (3): Sequential(
              (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (3): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (2): Sequential(
                (0): Conv2d(64, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(128, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Sequential(
              (0): Sequential(
                (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): Identity()
          )
        )
        (fuse_act): ReLU()
      )
      (2): HighResolutionModule(
        (branches): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=64, out_features=4, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=4, out_features=64, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=128, out_features=8, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=8, out_features=128, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=256, out_features=16, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=16, out_features=256, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
          (3): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=512, out_features=32, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=32, out_features=512, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (1): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=512, out_features=32, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=32, out_features=512, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (2): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=512, out_features=32, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=32, out_features=512, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
            (3): BasicBlock(
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (drop_block): Identity()
              (act1): ReLU(inplace=True)
              (aa): Identity()
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (act2): ReLU(inplace=True)
              (cbam): CBAM(
                (channel_attention): Channel_Attention(
                  (shared_mlp): Sequential(
                    (0): Flatten(start_dim=1, end_dim=-1)
                    (1): Linear(in_features=512, out_features=32, bias=True)
                    (2): ReLU(inplace=True)
                    (3): Linear(in_features=32, out_features=512, bias=True)
                  )
                )
                (spatial_attention): Spatial_Attention(
                  (compress): ChannelPool()
                  (spatial_attention): Sequential(
                    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                    (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
                  )
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): Identity()
            (1): Sequential(
              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=8.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Identity()
            (2): Sequential(
              (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Identity()
            (3): Sequential(
              (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (3): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (2): Sequential(
                (0): Conv2d(64, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(128, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Sequential(
              (0): Sequential(
                (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): Identity()
          )
        )
        (fuse_act): ReLU()
      )
    )
    (incre_modules): ModuleList(
      (0): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): ReLU(inplace=True)
          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (drop_block): Identity()
          (act2): ReLU(inplace=True)
          (aa): Identity()
          (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act3): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (cbam): CBAM(
            (channel_attention): Channel_Attention(
              (shared_mlp): Sequential(
                (0): Flatten(start_dim=1, end_dim=-1)
                (1): Linear(in_features=128, out_features=8, bias=True)
                (2): ReLU(inplace=True)
                (3): Linear(in_features=8, out_features=128, bias=True)
              )
            )
            (spatial_attention): Spatial_Attention(
              (compress): ChannelPool()
              (spatial_attention): Sequential(
                (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
        )
      )
      (1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (drop_block): Identity()
          (act2): ReLU(inplace=True)
          (aa): Identity()
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act3): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (cbam): CBAM(
            (channel_attention): Channel_Attention(
              (shared_mlp): Sequential(
                (0): Flatten(start_dim=1, end_dim=-1)
                (1): Linear(in_features=256, out_features=16, bias=True)
                (2): ReLU(inplace=True)
                (3): Linear(in_features=16, out_features=256, bias=True)
              )
            )
            (spatial_attention): Spatial_Attention(
              (compress): ChannelPool()
              (spatial_attention): Sequential(
                (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
        )
      )
      (2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (drop_block): Identity()
          (act2): ReLU(inplace=True)
          (aa): Identity()
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act3): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (cbam): CBAM(
            (channel_attention): Channel_Attention(
              (shared_mlp): Sequential(
                (0): Flatten(start_dim=1, end_dim=-1)
                (1): Linear(in_features=512, out_features=32, bias=True)
                (2): ReLU(inplace=True)
                (3): Linear(in_features=32, out_features=512, bias=True)
              )
            )
            (spatial_attention): Spatial_Attention(
              (compress): ChannelPool()
              (spatial_attention): Sequential(
                (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
        )
      )
      (3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act1): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (drop_block): Identity()
          (act2): ReLU(inplace=True)
          (aa): Identity()
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (act3): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (cbam): CBAM(
            (channel_attention): Channel_Attention(
              (shared_mlp): Sequential(
                (0): Flatten(start_dim=1, end_dim=-1)
                (1): Linear(in_features=1024, out_features=64, bias=True)
                (2): ReLU(inplace=True)
                (3): Linear(in_features=64, out_features=1024, bias=True)
              )
            )
            (spatial_attention): Spatial_Attention(
              (compress): ChannelPool()
              (spatial_attention): Sequential(
                (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
                (1): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
              )
            )
          )
        )
      )
    )
  )
  (decoder): UnetPlusPlusDecoder(
    (center): Identity()
    (blocks): ModuleDict(
      (x_0_0): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(1536, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention1): Attention(
          (attention): Identity()
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention2): Attention(
          (attention): Identity()
        )
      )
      (x_0_1): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(768, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention1): Attention(
          (attention): Identity()
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention2): Attention(
          (attention): Identity()
        )
      )
      (x_1_1): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention1): Attention(
          (attention): Identity()
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention2): Attention(
          (attention): Identity()
        )
      )
      (x_0_2): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention1): Attention(
          (attention): Identity()
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention2): Attention(
          (attention): Identity()
        )
      )
      (x_1_2): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention1): Attention(
          (attention): Identity()
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention2): Attention(
          (attention): Identity()
        )
      )
      (x_2_2): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention1): Attention(
          (attention): Identity()
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention2): Attention(
          (attention): Identity()
        )
      )
      (x_0_3): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(320, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention1): Attention(
          (attention): Identity()
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention2): Attention(
          (attention): Identity()
        )
      )
      (x_1_3): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention1): Attention(
          (attention): Identity()
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention2): Attention(
          (attention): Identity()
        )
      )
      (x_2_3): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention1): Attention(
          (attention): Identity()
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention2): Attention(
          (attention): Identity()
        )
      )
      (x_3_3): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention1): Attention(
          (attention): Identity()
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention2): Attention(
          (attention): Identity()
        )
      )
      (x_0_4): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention1): Attention(
          (attention): Identity()
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention2): Attention(
          (attention): Identity()
        )
      )
    )
  )
  (segmentation_head): SegmentationHead(
    (0): Conv2d(16, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): Identity()
    (2): Activation(
      (activation): Identity()
    )
  )
)
Number of train batches: 407
Number of val batches: 92
Adjusting learning rate of group 0 to 1.0000e-03.
Sanity Checking: 0it [00:00, ?it/s]Sanity Checking:   0%|                                                                                                                               | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|                                                                                                                  | 0/2 [00:00<?, ?it/s]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])
Sanity Checking DataLoader 0:  50%|█████████████████████████████████████████████████████                                                     | 1/2 [00:00<00:00,  1.11it/s]torch.Size([1, 3, 512, 512])
torch.Size([1, 512, 512])
Sanity Checking DataLoader 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.69it/s]                                                                                                                                                                           Training: 0it [00:00, ?it/s]Training:   0%|                                                                                                                                    | 0/497 [00:00<?, ?it/s]Epoch 0:   0%|                                                                                                                                     | 0/497 [00:00<?, ?it/s]Epoch 0:   0%|▎                                                                                                                            | 1/497 [00:01<10:32,  1.28s/it]Epoch 0:   0%|▏                                                                                                      | 1/497 [00:01<10:33,  1.28s/it, loss=0.642, v_num=74]Epoch 0:   0%|▍                                                                                                      | 2/497 [00:02<10:06,  1.22s/it, loss=0.642, v_num=74]Epoch 0:   0%|▍                                                                                                      | 2/497 [00:02<10:06,  1.22s/it, loss=0.581, v_num=74]Epoch 0:   1%|▌                                                                                                      | 3/497 [00:03<09:56,  1.21s/it, loss=0.581, v_num=74]Epoch 0:   1%|▋                                                                                                       | 3/497 [00:03<09:56,  1.21s/it, loss=0.54, v_num=74]Epoch 0:   1%|▊                                                                                                       | 4/497 [00:04<09:51,  1.20s/it, loss=0.54, v_num=74]Epoch 0:   1%|▊                                                                                                      | 4/497 [00:04<09:51,  1.20s/it, loss=0.512, v_num=74]Epoch 0:   1%|█                                                                                                      | 5/497 [00:05<09:48,  1.20s/it, loss=0.512, v_num=74]Epoch 0:   1%|█                                                                                                      | 5/497 [00:05<09:48,  1.20s/it, loss=0.489, v_num=74]Epoch 0:   1%|█▏                                                                                                     | 6/497 [00:07<09:45,  1.19s/it, loss=0.489, v_num=74]Epoch 0:   1%|█▏                                                                                                     | 6/497 [00:07<09:45,  1.19s/it, loss=0.465, v_num=74]Epoch 0:   1%|█▍                                                                                                     | 7/497 [00:08<09:43,  1.19s/it, loss=0.465, v_num=74]Epoch 0:   1%|█▍                                                                                                     | 7/497 [00:08<09:43,  1.19s/it, loss=0.448, v_num=74]Epoch 0:   2%|█▋                                                                                                     | 8/497 [00:09<09:41,  1.19s/it, loss=0.448, v_num=74]Epoch 0:   2%|█▋                                                                                                     | 8/497 [00:09<09:41,  1.19s/it, loss=0.428, v_num=74]Epoch 0:   2%|█▊                                                                                                     | 9/497 [00:10<09:39,  1.19s/it, loss=0.428, v_num=74]Epoch 0:   2%|█▊                                                                                                     | 9/497 [00:10<09:39,  1.19s/it, loss=0.423, v_num=74]